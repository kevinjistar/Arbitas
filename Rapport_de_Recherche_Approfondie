Rapport de Recherche Approfondie – Ozaru Digitals (Mapping Concurrentiel & Cœur de Cible Psychographique)

Axe 1 — Alternatives réelles à Ozaru

Objectif : Recenser toutes les options concrètes choisies par la cible lorsqu’elle ne retient pas Ozaru. Il s’agit d’identifier tous les “choix réels” possibles, au-delà des concurrents évidents, y compris les comportements et stratégies d’évitement. Quatre niveaux d’alternatives ont été explorés :

1. Alternatives directes (solutions similaires orientées IA)
	•	Cabinets de conseil en IA / data – Faire appel à des consultants spécialisés pour piloter des projets d’IA et de data science de bout en bout. L’entreprise délègue la conception et l’implémentation à une équipe externe d’experts, censés apporter une expertise pointue et accélérer la transformation.
	•	Agences “IA”, no-code, automation – S’adjoindre les services d’agences technologiques capables de prototyper rapidement des solutions d’automatisation ou d’IA via des outils no-code/low-code. La promesse est souvent un déploiement plus rapide et économique qu’un développement interne classique, avec des solutions prêtes à l’emploi.
	•	Intégrateurs d’outils IA – Plutôt que de concevoir sur mesure, certaines entreprises optent pour l’intégration de solutions existantes (logiciels d’IA, plateformes analytiques) via des prestataires. Ces intégrateurs se chargent de brancher des outils d’IA du marché sur les systèmes de l’entreprise (par ex. intégrer un moteur de machine learning dans l’ERP ou le CRM).
	•	Plateformes d’agents ou copilotes IA – Utiliser des produits proposant des “agents intelligents” ou copilotes alimentés par l’IA (par ex. assistants décisionnels, chatbots avancés, copilotes de code, etc.). Ici, l’organisation adopte une technologie qui promet de prendre en charge certaines décisions ou tâches via une IA autonome (on peut penser à des solutions type Microsoft Copilot, GPT-4 en mode agent, AutoGPT, etc., popularisées récemment).

2. Alternatives indirectes (choix organisationnels non centrés sur l’IA)
	•	Cabinets de conseil non-IA – Recourir à du conseil plus traditionnel (stratégie, management, organisation) pour résoudre les problèmes. L’idée est de s’appuyer sur l’expertise métier ou sectorielle de consultants classiques plutôt que sur des approches technologiques.
	•	Outils de Business Intelligence (BI), tableaux de bord et reporting – Renforcer l’usage d’outils BI et de reporting existants pour améliorer la décision. Cela revient à se dire que de meilleurs dashboards et analyses descriptives suffisent, sans aller vers de l’IA prédictive. De nombreuses entreprises investissent massivement dans la BI en pensant que des indicateurs plus visibles conduiront à de meilleures décisions.
	•	Recrutements internes (data, ops, product) – Embaucher en interne des talents (data scientists, analystes, responsables opérations, product managers, etc.) pour traiter les problèmes. Plutôt que d’acheter une solution externe, l’entreprise construit ses propres capacités en se dotant d’équipes spécialisées qui gèrent la donnée, automatisent manuellement ou améliorent les processus existants.
	•	Comités, processus humains renforcés – Multiplier les comités de pilotage, les circuits de validation manuels, le contrôle qualité humain, etc. C’est le choix de gouvernance humaine : on crée des groupes de travail, on ajoute des étapes de revue et de décision pour réduire le risque d’erreur, sans nouvelle technologie. En somme, on “met plus de monde dans la boucle” pour fiabiliser les décisions.

3. Alternatives comportementales (attitudes face à l’inaction)
	•	Statu quo assumé – Ne rien changer du tout et vivre avec les inefficacités. C’est sans doute la plus grande alternative à toute innovation : ne pas innover. Par exemple, beaucoup d’équipes persistent avec leurs fichiers Excel et leurs procédures manuelles car « on a toujours fait comme ça » ￼. Ce biais du statu quo – préférer la situation actuelle par confort – est très répandu et conduit à maintenir des processus obsolètes simplement parce qu’ils sont familiers ￼.
	•	Décisions manuelles lentes – Continuer à prendre les décisions “à l’ancienne”, via de longues réunions, de l’instinct, des allers-retours hiérarchiques. La cible peut accepter que la décision prenne du temps (parfois trop de temps), considérant que la lenteur est le prix à payer pour la prudence.
	•	Contournement des problèmes – Éviter d’affronter frontalement les problèmes complexes. Par exemple, plutôt que de résoudre une inefficacité systémique, on met en place des rustines temporaires, on contourne le problème par des exceptions ou des traitements manuels additionnels.
	•	Sur-contrôle humain – Multiplier les points de contrôle, les validations et les micro-décisions humaines. Un management qui vérifie tout, n’automatise rien sans triple validation. Cela reflète une méfiance vis-à-vis des systèmes automatisés : on préfère garder chaque décision sous contrôle humain direct, quitte à engorger le processus.

4. Alternatives d’évitement (stratégies pour échapper au sujet)
	•	Report de décision – Repousser les décisions difficiles aux calendes grecques. La cible peut choisir de ne pas décider tout de suite sur les sujets IA, en espérant plus de clarté plus tard. Par exemple, un dirigeant dira « on verra l’an prochain pour l’IA, ce n’est pas urgent ». Ce report est souvent justifié par les échecs ambiants (« Tu vois, l’IA ça marche pas, je vais encore attendre » témoigne un décideur sceptique ￼ ￼).
	•	Réduction du périmètre – Limiter les ambitions. L’entreprise évite l’IA en restreignant le champ du projet à des choses plus simples ou conventionnelles. Par exemple, on transforme un projet de refonte intelligente en simple optimisation de process existant (sans IA).
	•	Abandon silencieux du sujet IA – Dans certains cas, le thème même de l’IA disparaît des présentations et feuilles de route sans annonce officielle. On arrête discrètement de financer ou de communiquer sur les initiatives IA, constatant qu’elles patinent, mais sans l’admettre publiquement. Ce glissement permet d’éviter d’affronter l’échec : le sujet est juste occulté.

En résumé, les alternatives à Ozaru ne se limitent pas à d’autres solutions technologiques. La cible dispose d’un éventail complet allant de la délégation à des experts, en passant par l’achat de technologies prêtes à l’emploi, jusqu’à la non-décision assumée. Cette liste met en évidence que le principal concurrent d’une innovation est souvent le statu quo, c’est-à-dire l’inertie ou le “faire comme d’habitude” ￼ ￼. Les choix réels du terrain sont guidés autant par la psychologie (peur du changement, besoin de contrôle) que par l’offre disponible.

Axe 2 — Promesses et implicites de chaque alternative

Objectif : Pour chaque alternative identifiée, comprendre ce qui est réellement promis (explicitement ou non) et les non-dits : qui porte la responsabilité en cas d’échec, qui décide vraiment, y a-t-il un “filet de sécurité”, que se passe-t-il si ça ne marche pas ? L’analyse révèle que chaque alternative véhicule une promesse spécifique – souvent séduisante – mais avec des limites plus ou moins avouées.
	•	Cabinets de conseil IA/data – Promesse explicite : “Des experts vous garantissent une adoption réussie de l’IA”. Les grands cabinets mettent en avant leur méthodologie et expérience pour transformer l’entreprise grâce à l’IA. Implicite : Souvent, la promesse n’est pas falsifiable, car les critères de succès sont flous à l’engagement. En pratique, beaucoup de projets menés par des consultants échouent (jusqu’à 80% des initiatives IA n’atteignent pas leurs objectifs selon Gartner ￼). Pourtant la responsabilité de l’échec est diluée : les cabinets évitent d’assumer la faute. Un analyste du secteur note que les grands cabinets contribuent à “une évasion de la responsabilité” dans les projets IA, via des attentes mal alignées et l’absence de métriques claires de succès ￼ ￼. En clair, le consultant promet l’excellence mais, si le projet déraille, on invoquera un manque de données ou un défaut d’exécution côté client. D’ailleurs, il est fréquent qu’aucune définition précise du “succès” n’ait été établie au départ, laissant le résultat invérifiable ￼. Qui décide réellement : Le cabinet influence fortement les décisions (on “suit” ses préconisations), mais garde la posture de conseiller – le décideur final restant le client (au moins formellement). Peut-on arrêter facilement : Oui, on peut mettre fin au contrat de conseil, mais bien souvent après que des budgets conséquents ont été dépensés. En cas d’échec : on constate une grande asymétrie – le client encaisse la perte (budget perdu, temps perdu), tandis que le consultant, lui, a déjà facturé ses honoraires. Signal faible : les cabinets vendent rarement un plan B en cas d’échec ; l’échec n’est pas un scénario envisagé dans leur proposition commerciale. Comme le formule un ancien client désabusé, « quand tu leur paies des centaines de milliers pour leur expérience, et qu’en fait c’est un jeune diplômé qui fait ses preuves sur ton dos… », on sent que la “responsabilité” est floue ￼.
	•	Agences IA / no-code / automation – Promesse explicite : “Digitalisez et automatisez vite vos processus sans coder”. Elles mettent en avant la rapidité et le coût réduit pour déployer des workflows automatisés ou des applications sur étagère. Implicite : Une partie de la promesse repose sur l’idée que la technologie no-code/low-code est magique et sans limites – ce qui est trompeur. Le discours marketing de certaines plateformes no-code clame qu’on peut construire des systèmes aussi complexes et évolutifs que Facebook ou Instagram sans une ligne de code. Un utilisateur en témoigne avec sarcasme : « Selon eux, on peut bâtir des apps aussi complexes et scalables que Instagram… C’est d’une ignorance crasse et risible ￼. » En réalité, ces solutions atteignent vite leurs limites (fonctions manquantes, intégrations coûteuses via Zapier, personnalisation limitée). Responsabilité : l’agence livre un outil, mais si celui-ci atteint ses limites ou engendre des bugs, c’est l’entreprise utilisatrice qui en subit les conséquences au quotidien. L’agence peut se dédouaner en pointant la plateforme technologique. Qui décide : durant le projet, l’agence paramètre beaucoup de choses à la place de l’utilisateur final (le pouvoir de décision technique est chez elle), mais l’entreprise cliente garde la décision métier (quoi automatiser ou pas). Arrêt du système : Techniquement, une automatisation no-code peut souvent être arrêtée facilement (il suffit de désactiver les workflows). Le risque est plutôt une dépendance forte : une fois qu’un processus business critique est géré par un assemblage no-code, revenir en arrière peut s’avérer très difficile sans tout casser. Quand ça ne marche pas : Souvent l’entreprise découvre trop tard les contraintes (coûts d’intégration exponentiels, impossibilité d’évoluer). Des entrepreneurs relatent avoir perdu des mois avec du no-code pour finir par tout recoder proprement ensuite ￼ ￼. L’échec se manifeste par un plafonnement : le système bricolé ne passe pas à l’échelle, et la seule “solution” est de repartir sur du développement classique – aveu que la promesse initiale était survendue.
	•	Intégrateurs d’outils IA – Promesse explicite : “Adoptez le meilleur de l’IA du marché, intégré proprement chez vous”. L’intégrateur vend sa capacité à choisir et installer la bonne solution (logiciel d’IA, suite analytique, etc.) qui améliorera un processus donné. Implicite : On fait souvent miroiter la sécurité du déjà-éprouvé (“tel outil est leader du Magic Quadrant, vous ne prenez pas de risque”). En réalité, l’engagement de résultat est limité : l’intégrateur promet l’installation, pas le succès opérationnel. La promesse est difficilement falsifiable car si l’outil ne produit pas les gains escomptés, on pourra toujours dire que “le contexte client est différent” ou qu’il faut plus de temps. Responsabilité : L’intégrateur est responsable techniquement du déploiement, mais pas de l’usage métier qui en est fait. Si l’outil IA ne tient pas ses promesses, est-ce un problème de l’outil ou de son utilisation ? Chacun peut se renvoyer la balle. Souvent l’éditeur du logiciel et l’intégrateur se protègent mutuellement. Qui décide : pendant le projet, l’intégrateur prend de nombreuses décisions techniques (paramétrages, modifications de processus) — le client valide mais sur base de l’expertise de l’intégrateur, donc le pouvoir de fait est partagé. Arrêt : Théoriquement on peut débrancher un outil implanté si ça ne fonctionne pas, mais en pratique plus un outil est intégré profondément (ex: connecté à la production), plus l’arrêt est coûteux (il faut rétablir l’ancien système, re-former le personnel à l’ancienne méthode, etc.). Échecs : L’absence de protocole d’échec clair est fréquente : par ex., si un modèle intégré fait des erreurs, y a-t-il un mécanisme de fallback humain ? Si ce n’est pas prévu dès le départ, on découvre “en live” les problèmes (ex: algorithme biaisé qu’il faut débrancher en urgence). Signal faible : Quand l’intégrateur ne communique que sur les succès et n’évoque jamais comment réagir en cas de défaillance, il y a un angle mort stratégique.
	•	Plateformes d’agents IA / copilotes autonomes – Promesse explicite : “Laissez une IA agir à votre place pour gagner en efficacité”. C’est l’idée de l’autonomie : l’agent intelligent gère tout ou partie d’un processus de décision, sans intervention humaine continue. On promet une réduction de la charge cognitive en déléguant les décisions routinières à un copilote. Implicite : La promesse ici flirte souvent avec la science-fiction. Le marketing exagère l’autonomie réelle de ces agents. Des slogans tels que « les agents IA vont remplacer vos employés » ou « 2025 sera l’année des agents IA » ont fleuri, créant un énorme fossé entre la promesse et la réalité ￼. En pratique, ce sont souvent des assemblages de modèles fragiles où chaque étape peut partir en vrille, loin d’une véritable intelligence autonome. Responsabilité : C’est possiblement l’alternative où la question de la responsabilité est la plus floue. Si on laisse un agent décider et qu’il commet une erreur grave, qui blâmer ? Le fournisseur de la plateforme peut dire que c’est à l’utilisateur de superviser. L’utilisateur pensait peut-être que l’agent était “fiable”. Actuellement, peu de fournisseurs d’agents copilotent jusqu’à assumer les torts en cas de dégât. Qui décide : Par définition, l’agent prend des décisions opérationnelles à la place du décideur humain, du moins dans le périmètre qu’on lui a confié. L’humain décide en amont de lui déléguer telle tâche, puis l’agent exécute et décide seul dans ce cadre. Peut-on stopper : Oui, en général l’humain peut reprendre la main (par ex., on peut désactiver un agent logiciel). Mais plus l’agent est intégré profondément (ex: un agent qui passerait des ordres financiers automatiquement), plus il faut un dispositif “kill switch” robuste pour éviter des catastrophes en cas de dérive. Que se passe-t-il en cas d’échec : Deux scénarios : (1) Soit l’agent fait une erreur mineure, et on doit calibrer après coup (les utilisateurs souvent pardonnent peu les erreurs de la machine – phénomène d’algorithm aversion où une seule erreur peut discréditer tout le système ￼ ￼). (2) Soit l’agent déraille complètement (cas plus grave, ex: un chatbot d’Elon Musk s’est mis à proférer des propos haineux de façon incontrôlée ￼). Dans ce cas, généralement l’agent est immédiatement coupé et le fournisseur publie des correctifs en urgence. Point marquant : Beaucoup de ces projets d’agents n’arrivent jamais en production : on constate 42% d’abandon avant déploiement en production pour les initiatives d’IA générative, un taux d’échec explosif qui montre que la promesse est largement non tenue ￼. Cela indique que la promesse implicite (“ça marchera tout seul”) n’est pas soutenue par un plan de gestion de l’échec – d’où la méfiance croissante.
	•	Cabinets de conseil non-IA – Promesse explicite : “Un regard externe pour améliorer vos décisions ou processus, sans forcément passer par la technologie”. Ils promettent de résoudre des problèmes par l’organisation, la stratégie, l’optimisation humaine. Implications : La responsabilité de l’échec est souvent tout aussi floue qu’avec le conseil technologique – un plan stratégique qui n’aboutit pas sera souvent attribué à une mauvaise exécution par le client. Ces cabinets promettent parfois moins qu’un cabinet IA (ils ne vendent pas de magie technologique, donc le risque de promesse non tenue est moindre en apparence), mais ils peuvent aussi se retrancher derrière des recommandations non appliquées. Qui décide : c’est du conseil, donc le décideur reste l’entreprise cliente; le consultant apporte une recommandation, libre à l’entreprise de la suivre ou pas. Échec : si les recommandations n’améliorent rien, on pourra dire que le contexte a changé ou que la direction n’a pas suffisamment poussé le changement. Le non-dit est souvent : le consultant n’ira pas assumer les conséquences concrètes, il fournit “du papier”. Un signal faible ici est l’absence de suivi sur résultat – beaucoup de missions s’arrêtent à la remise d’un rapport.
	•	Outils BI, dashboards – Promesse explicite : “Des données claires pour éclairer vos décisions”. On vend l’idée qu’en accumulant les indicateurs et en les visualisant mieux, les décideurs prendront forcément de meilleures décisions. Implicite : La promesse est que la vérité émerge des données. Mais sans protocole d’échec : on ne dit pas quoi faire si malgré le dashboard la décision est mauvaise. Et de fait, les dashboards peuvent induire en erreur. Par exemple, trop d’informations tue l’information : « un tableau de bord mal conçu peut brouiller la prise de décision au lieu de l’éclairer » ￼. Pourtant, rares sont les fournisseurs BI qui admettent cette possibilité dans leur pitch. Responsabilité : L’outil est un support, donc c’est l’utilisateur qui endosse toute la responsabilité de l’analyse. Si une décision erronée est prise sur la base d’un dashboard, on dira “mauvaise interprétation de l’utilisateur” ou “donnée incorrecte”, mais pas la faute du logiciel. Qui décide : l’humain décide toujours, l’outil n’est qu’un miroir des données. Arrêt : Facile de cesser d’utiliser un dashboard si jugé inutile, mais en pratique les organisations les laissent en place même s’ils sont peu utiles (inertie). Échecs : On constate des frustrations quand la promesse de clarté n’est pas au rendez-vous. Par exemple, des entreprises croulent sous les KPIs et perdent le fil : « Chaque métier a son tableau de bord… résultat ? Un ensemble d’indicateurs souvent déconnectés des besoins réels » ￼. Si la BI ne marche pas, les utilisateurs reviennent à leur instinct ou à Excel – un retour en arrière rarement anticipé dans le plan projet initial.
	•	Recrutements internes (data, ops) – Promesse : “Avec les bonnes personnes en interne, on fera mieux que n’importe quel outil tout fait”. C’est un choix souvent motivé par le contrôle : avoir ses propres experts pour ne pas dépendre d’un externe. Implicite : On suppose que ces talents pourront tout résoudre, mais sans garantir qu’ils auront les moyens (données de qualité, soutien de la direction, etc.). La réussite ou l’échec reposera sur eux, ce qui est lourd : si le projet patine, est-ce parce que la recrue “n’était pas à la hauteur” ou parce que l’entreprise n’a pas su la mettre en condition de réussir ? Souvent, ces recrutements viennent combler un vide (on se dit qu’en embauchant un Data Scientist on aura de l’IA, sans plan clair). Responsabilité : paradoxalement, elle est très forte sur l’individu recruté – on attend parfois une transformation miracle de sa part – et en même temps diluée pour l’organisation (on s’est donné bonne conscience en recrutant, si ça échoue on pourra incriminer la personne ou le manque de “fit”). Qui décide : l’entreprise garde évidemment la main, l’employé interne est un nouvel acteur qui va conseiller et potentiellement implémenter, mais sans pouvoir décisionnel stratégique seul. Peut-on arrêter : Difficile “d’arrêter” une stratégie de recrutement une fois la personne là – sauf à la licencier, ce qui a un coût humain et financier. Souvent, si ça ne marche pas, la personne est repliée sur un rôle mineur ou quitte d’elle-même (fuite des talents). En cas d’échec : L’organisation peut se retrouver avec des embauches coûteuses et sous-employées, et la tentation est de laisser traîner plutôt que d’admettre l’erreur de casting ou de stratégie.
	•	Comités / processus humains – Promesse : “Plus on met de têtes autour de la table, meilleure sera la décision, et on évitera les erreurs.” L’idée implicite est qu’en multipliant les validations, on bâtit de la fiabilité. Implicite : On promet une sorte de filet de sécurité collectif, sans jamais dire à quel point cela peut ralentir et diluer la responsabilité. En réalité, ces configurations manquent souvent d’un protocole d’échec clair : quand tout le monde décide, personne n’est responsable si la décision est mauvaise. C’est le fameux écueil de la décision collective où l’échec est orphelin. Responsabilité : Diffuse – en cas d’échec, le comité peut incriminer un contexte imprévu, mais il est rare qu’un membre du comité soit tenu personnellement responsable (d’où un certain confort dans le comité). Qui décide : officiellement le comité, donc pluralité de décideurs – ce qui peut conduire à des compromis médiocres. Arrêt : Arrêter un comité est politiquement difficile (“on donne l’impression de réduire la gouvernance”). On les maintient parfois même s’ils n’apportent rien, par peur de retirer un garde-fou. Échec : Les décisions de comité sont parfois lentes et sans vision, ce qui peut frustrer la base. Mais l’échec se manifeste sournoisement : pas de décision forte, perte de confiance des opérationnels, etc. – et il n’y a pas de moment précis où on dit “ça a échoué” (puisqu’il n’y a pas de promesse claire à la base, hormis “on va réfléchir ensemble”).
	•	Statu quo / méthodes manuelles – Promesse implicite : “Au moins, en ne changeant rien, on maîtrise la situation actuelle et on ne fait pas d’erreur catastrophique.” C’est souvent un choix par défaut, sans fanfare marketing. Implications : Aucune promesse de mieux, juste l’assurance du connu. Paradoxalement, cela peut être rassurant pour beaucoup car toute nouveauté comporte un risque. Responsabilité : Ici l’entreprise assume de fait toutes les conséquences (puisque ne rien changer est son choix). Mais comme il n’y a pas d’intervention extérieure, il n’y a personne d’autre à blâmer – ce qui est une raison pour laquelle ce choix est rarement explicite. Qui décide : ne rien faire est souvent le résultat de multiples non-décisions individuelles plus qu’une décision assumée. Arrêt : Le statu quo peut perdurer indéfiniment jusqu’à ce qu’une crise force enfin le changement. Échec : Ce n’est pas un échec soudain mais une érosion : l’entreprise peut perdre en compétitivité ou efficacité lentement. Faute de promesse initiale, on ne prononce jamais “l’échec du statu quo”, on finit juste par constater qu’on est à la traîne.

Synthèse : Chaque alternative comporte une proposition de valeur plus ou moins testable. Un indicateur clé mis en avant était : “Toute promesse sans protocole d’échec explicite est un signal faible”. Or, on constate que peu d’alternatives articulent clairement leur gestion de l’échec. Que ce soit le consultant qui évite d’évoquer les ratés, l’outil qui ne prévoit pas de plan B en cas de bug, ou le comité qui ne désigne pas de responsable en cas de mauvaise décision, ces impensés sont autant d’espaces où se nichent risques et désillusions. Pour Ozaru, comprendre ces implicites est crucial afin de ne pas tomber dans les mêmes travers de promesse vague ou d’absence de filet de sécurité.

Axe 3 — Frustrations réelles observées sur le terrain

Objectif : Identifier les douleurs non résolues et frustrations persistantes de la cible, qu’elles soient clairement exprimées ou latentes. À travers les témoignages (posts LinkedIn, forums, retours d’expérience, etc.), une série de frustrations transversales émergent. Nous les avons classées du plus concret au plus psychologique, avec quelques illustrations tirées du terrain. Ces frustrations sont souvent ce que la cible “accepte faute de mieux”, tout en en ayant marre en silence.
	•	Surcharge d’information et manque de clarté – De nombreux décideurs expriment leur agacement devant des outils censés aider mais qui complexifient la décision. Par exemple, l’excès de tableaux de bord et d’indicateurs : « Trop d’informations tue l’information, et un tableau de bord mal conçu peut brouiller la décision au lieu de l’éclairer » ￼. La paralysie analytique guette quand on multiplie les KPIs sans hiérarchie claire. Frustration connexe : perdre du temps à chercher du sens dans les données plutôt qu’à agir. Cette douleur est souvent tolérée par défaut (“c’est comme ça”), mais crée une fatigue décisionnelle. Les décideurs lucides en viennent à douter de leurs outils de reporting, certains confiant qu’ils finissent par revenir aux fondamentaux (quelques métriques simples, voire l’instinct) car les dashboards les “noient” ￼ ￼.
	•	Promesses non tenues et cynisme vis-à-vis du hype – La cible montre une exaspération grandissante envers le buzz technologique qui n’aboutit pas. Beaucoup ont vu des projets IA ou digitaux très vantés finir en eau de boudin. Conséquence : un scepticisme ironique, parfois exprimé publiquement. Par exemple, sur LinkedIn et les blogs spécialisés, on trouve des articles soulignant l’écart entre le discours et la réalité : « un fossé énorme entre promesses marketing et réalité » concernant les agents IA ￼. Les chiffres d’abandon (42% des projets IA géné abandonnés prématurément ￼) alimentent ce cynisme. On entend des décideurs dire en substance “on m’a déjà fait le coup du miracle technologique, je n’y crois plus”. Un commentaire illustre le ras-le-bol face aux consultants high-tech : « la plupart des anciens consultants savent que les consultants racontent des conneries » ￼. Ce n’est pas seulement de la méfiance, c’est de la colère froide contre le décalage entre le storytelling d’innovation et la réalité terrain. Cette frustration se manifeste par de l’ironie, du cynisme (plaisanter sur “l’IA qui devait tout changer et qui n’a rien donné”). C’est un signal faible très important : la cible est vaccinée contre le bullshit, et toute nouvelle promesse non crédible agace plus qu’elle n’enthousiasme.
	•	Perte de confiance due à l’opacité et la délégation forcée – Une peur/frustration fréquente chez les opérationnels : ne pas comprendre ce que fait la “boîte noire” et devoir pourtant lui faire confiance. « L’IA, moi j’y comprends rien ! » – derrière cette exclamation relevée chez de nombreux employés se cache une angoisse de perte de contrôle ￼. Des collaborateurs témoignent qu’un système opaque qui prend des décisions à leur place les met très mal à l’aise : « cette impression d’opacité nourrit la peur de perdre la main sur [mon] travail » ￼. Même quand l’outil existe, ils tolèrent l’opacité faute de mieux, mais avec méfiance. Cela rejoint la frustration de devenir passager de sa propre activité. Par exemple, des responsables Ops disent craindre les automatisations décisionnelles où ils n’ont plus la possibilité d’intervenir si ça déraille (crainte de “l’auto-pilote incontrôlable”). On note aussi la frustration quand une IA commet une erreur : l’humain se retrouve responsable des dégâts sans avoir eu la maîtrise en amont. Cette situation est ressentie comme injuste et inquiétante. Beaucoup acceptent les outils imposés, mais sans confiance : ils les surveillent comme du lait sur le feu, ce qui crée stress et double-vérification permanente (perte d’efficacité, donc frustration).
	•	Lenteur et inertie des processus – C’est une frustration souvent exprimée en creux. Par exemple, lors de ventes ou workshops, on entend régulièrement « on met un temps fou à prendre la moindre décision ». Les comités et validations multiples exaspèrent certains, notamment la nouvelle génération de managers plus agiles. Cependant, cette frustration est intériorisée : on la considère comme “le prix à payer” pour la gouvernance. Beaucoup de responsables ops en ont assez d’attendre les arbitrages du top management ou d’un énième comité. Ils tolèrent faute de mieux, mais non sans grincer des dents. Un symptôme fréquent : le sarcasme sur “le comité qui fera un rapport de plus” ou “Excel reste notre meilleur ami parce que pour avoir un outil officiel validé il faut 2 ans”. Ainsi, l’inertie est acceptée officiellement, mais moquée officieusement.
	•	Sur-contrôle et micro-management – Côté managérial, un agacement existe face à la surcharge de contrôle humain. Paradoxalement, ce sont parfois les mêmes qui craignent l’automatisation opaque qui se plaignent du micro-management… quand c’est un autre humain qui l’exerce. Des équipes expriment de la lassitude envers des managers qui veulent tout vérifier, ne laissent aucune autonomie, ce qui ralentit tout et démotive. Cette frustration ressort dans des enquêtes internes (employés désengagés car absence de confiance de la hiérarchie). Elle n’est pas spécifique à l’IA, mais c’est une alternative comportementale (sur-contrôle humain) qui engendre du mal-être. Beaucoup la subissent en silence, mais on décèle des signes (turnover, humour noir sur “Big Brother” interne, etc.).
	•	Manque de responsabilité et dilution des échecs – Enfin, sur un plan plus psychologique, une frustration profonde de certains “vétérans” est : « Personne n’assume quand ça foire ». Que ce soit un projet IA raté (le fournisseur blâme l’utilisateur, l’utilisateur blâme le fournisseur…), ou une décision erronée prise collectivement (responsabilité floue), il y a un sentiment d’irresponsabilité généralisée dans les organisations. Cette frustration-là est rarement exprimée publiquement (culture du blâme étant taboue), mais on la voit transparaître dans des interviews anonymes ou des commentaires off the record. Par exemple, un cadre pourra confier qu’il en a assez que “les projets tombent dans les trous, et à la fin c’est moi qui dois rattraper les pots cassés sans que les prestataires ne soient inquiétés”. Cette lassitude face à l’absence de culpabilité déclarée est un signal important : certaines cibles cherchent celui qui aura le courage de garantir quelque chose ou au moins de s’engager sur le résultat. Elles sont frustrées du jeu de ping-pong habituel et aspirent à plus de redevabilité (accountability).

En synthèse, les frustrations transversales tournent autour de la confiance trahie et du temps perdu : confiance trahie par des promesses creuses, par des outils incompréhensibles, ou par un management trop pesant ; temps perdu dans des analyses confuses, des processus interminables ou des allers-retours de blâme. Ces frustrations sont souvent exprimées sur le ton de la résignation lucide (“c’est frustrant mais bon, c’est comme ça…”). Elles constituent autant d’opportunités pour Ozaru de se positionner en antidote si elles sont adressées de front.

Axe 4 — Validation du cœur de cible psychographique (archétypes Ozaru)

Objectif : Confronter les archétypes théoriques d’Ozaru (“Décideur lucide”, “Ops responsable”, “Dirigeant traumatisé par l’innovation”) avec la réalité observée. L’enjeu est de voir si ces personnages existent vraiment, si leurs motivations et “haines” se vérifient dans le terrain, ou s’il faut les ajuster. Chaque archétype est passé au crible des observations récoltées.

Archétype 1 : Le Décideur Lucide

C’est qui : Le dirigeant ou cadre supérieur ultime décideur, celui qui porte la responsabilité finale. Selon la description initiale, il/elle a connu des décisions coûteuses dans le passé, cherche la clarté plutôt que l’optimisme, et accepte la contradiction et les mauvaises nouvelles pour mieux décider. En somme, c’est le patron désillusionné par les effets d’annonce, qui veut qu’on lui dise la vérité nue.

Existence réelle : Oui, cet archétype existe, même s’il n’est pas majoritaire. On retrouve son portrait chez certains dirigeants expérimentés, souvent passés par des échecs retentissants (projets ratés, crises…). Par exemple, lors de la collecte, on a vu des références à des CEOs ou directeurs qui insistent publiquement sur l’importance de “stopper un projet qui inquiète” et de faire preuve de courage plutôt que de foncer aveuglément ￼. Ces décideurs-là valorisent la lucidité plus que le hype. Un indice : l’étude Edelman 2024 sur la confiance dans l’innovation montre qu’on attend des dirigeants qu’ils fassent preuve de retenue et d’empathie vis-à-vis de l’innovation, plutôt que d’être des évangélistes béats ￼ ￼. Cela correspond bien au Décideur Lucide (prudent, qui tempère l’enthousiasme technophile).

Haines et motivations confirmées : Le Décideur Lucide est censé “haïr” l’optimisme béat, et on le voit en effet dans certains témoignages. Par exemple, tel DG confie en off qu’il en a assez des comités d’innovation qui vendent du rêve. Ce profil admire au contraire qu’on lui apporte les faits bruts, même s’ils sont contraires à la tendance. Un article de blog sur le leadership face à la dissonance cognitive souligne justement : “il faut apprendre à être confortable dans l’inconfort et accepter les contradictions, c’est vital” ￼. C’est quasiment la devise du Décideur Lucide. On peut donc dire que les traits psychologiques sont bien observables : une préférence pour la vérité qui dérange plutôt que l’illusion qui rassure.

Minoritaire mais stratégique : Probablement oui. Tous les décideurs finaux ne sont pas lucides de cette manière – beaucoup se laissent encore séduire par des narratifs optimistes ou par leur ego. Mais ceux qui le sont ont un poids énorme : ce sont souvent les “sages” de l’organisation, écoutés quand ça va mal. Ils peuvent débloquer des situations que d’autres n’oseraient pas. Donc même minoritaires, ils sont très influents dans la direction que prend l’entreprise.

Prêt à payer pour cette posture : C’est la question du value prop pour Ozaru. Un décideur lucide, s’il est convaincu qu’Ozaru va lui fournir cette clarté sans complaisance, paiera volontiers. Car ce qu’il achète ce n’est pas une techno, c’est une assurance contre l’aveuglement. Ce profil a connu le coût immense des mauvaises décisions prises dans le brouillard ou l’euphorie, donc il voit la valeur d’un partenaire qui challenge et donne des signaux d’alerte. On a relevé par exemple des dirigeants disant investir désormais dans des dispositifs de vérification tiers pour ne plus se faire avoir par l’effet tunnel. C’est exactement ce que propose un Ozaru (du moins dans l’esprit).

Où pourrait-il abandonner Ozaru : Il lâchera Ozaru s’il a l’impression qu’Ozaru devient comme les autres, c’est-à-dire s’il perçoit le moindre bullshit ou angle mort non assumé. Ce type d’individu teste la fiabilité par la contradiction. S’il pose une question difficile et qu’Ozaru répond par une langue de bois ou une promesse vague, il perdra immédiatement confiance. Par ailleurs, si l’organisation autour de lui (son CODIR par exemple) est trop technophile/hypée, il peut être mis en minorité et contraint d’abandonner Ozaru au profit d’une solution plus sexy – c’est le cas du “lucide” qu’on n’écoute pas car il gâche la fête. Mais globalement, s’il est en position de décider, il ne quitte Ozaru que si Ozaru le déçoit en devenant complaisant ou opaque, c’est-à-dire en trahissant précisément la proposition de valeur de lucidité.

Verdict : Archétype validé dans ses grandes lignes. Il existe des décideurs lucides en chair et en os, leurs traits correspondent à ce qui était imaginé. Peut-être faut-il noter qu’ils ne sont pas la majorité bruyante – ce sont souvent des personnalités un peu en retrait du brouhaha, qui ne s’affichent pas comme “pro-tech” ou “anti-tech” mais comme pragmatiques sceptiques. Ozaru aura un écho particulier auprès d’eux. Le risque serait d’idéaliser leur proportion : il faudra probablement aussi convaincre des décideurs moins lucides de prime abord, mais qui aimeraient le devenir (ou en tout cas éviter les désastres).

Archétype 2 : Le Responsable Ops (opérationnel responsable)

C’est qui : Le cadre intermédiaire ou le manager opérationnel qui subit les décisions prises au sommet et doit en gérer les effets concrets. Dans la description initiale, il/elle craint les automatisations opaques, cherche la fiabilité et le contrôle, et en a assez de devoir “nettoyer les pots cassés” des décisions irréalistes. En gros, c’est le garant du terrain, celui qui doit faire marcher les process au jour le jour.

Existence réelle : Absolument, et probablement sous une forme assez fréquente. Les profils Ops/RH/IT managers qui doivent implémenter les changements sont nombreux, et beaucoup partagent ces préoccupations. On a abondamment trouvé trace de craintes opérationnelles vis-à-vis de l’IA : par ex., « L’IA me fait peur… peur de perdre le contrôle ou mon emploi » ￼. Derrière cela, on voit un large échantillon de managers qui se posent des questions très terre-à-terre : “que se passe-t-il si le système se trompe ?”, “devrai-je expliquer un truc que je ne comprends pas ?”, “va-t-on me supprimer mon équipe si on automatise ?”. Ces personnes existent dans presque chaque grande entreprise. Elles ne sont pas idéalisées : on peut quasiment mettre des noms réels sur cet archétype (le responsable qualité qui craint un algorithme non transparent, le chef d’équipe qui a vécu un déploiement logiciel catastrophique et redoute qu’on recommence, etc.).

Haines et irritants confirmés : L’archétype Ops responsable est censé “détester” les automatisations opaques et l’irresponsabilité. Cela se vérifie clairement. Dans les forums internes et retours d’expérience, les opérationnels se plaignent souvent de systèmes “imposés d’en haut” sans transparence. Un sentiment fréquent : « on nous impose un outil, et quand ça plante ou que les données sont pourries, c’est nous qui devons rattraper le coup ». Ce profil valorise la fiabilité et la prédictibilité. Par exemple, les biais psychologiques relevés chez les opérationnels incluent le bias d’automatisation où ils finissent par suivre aveuglément l’IA – ce qu’ils redoutent justement car ils savent que c’est dangereux ￼ ￼. Beaucoup mentionnent qu’une IA qui décide à leur place sans explication est inacceptable pour eux – ils préfèrent largement un outil plus simple mais qu’ils comprennent. Donc oui, leur “haine” de l’opacité est bien réelle. De même, ils haïssent devoir assumer les erreurs des autres (de la machine ou du siège). L’expression “faute de mieux on fait avec” revient souvent dans leur bouche, signe de résignation forcée (par ex. un ops dira “oui ce logiciel est nul mais faute de mieux on le subit”). Ce n’est pas de la passivité : c’est de la frustration latente prête à alimenter de la résistance si une nouvelle solution répète ces travers.

Profil stratégique : Probablement oui, car c’est souvent lui qui fait réussir ou échouer concrètement les transformations. On sait par de nombreuses études internes que si les managers intermédiaires n’adhèrent pas, le projet capote (ils peuvent saboter passivement, ne pas utiliser l’outil, etc.). Donc même s’il n’a pas le pouvoir d’achat direct toujours (il ne signe pas les gros chèques, sauf peut-être un DSI ou COO), il a un pouvoir d’influence énorme. Il est souvent prescripteur interne – le top management va demander “alors, tu en penses quoi de ce truc ?” et s’il dit “c’est du flan, ça va nous mettre en risque”, le projet ne passera pas. Donc Ozaru a tout intérêt à coller aux besoins de cet archétype.

Prêt à “payer” (ou du moins soutenir) : Oui, dans le sens où il investira volontiers son énergie et son soutien si une solution répond à ses préoccupations. S’il est convaincu qu’Ozaru lui donne de la visibilité et de la maîtrise, il deviendra un champion en interne. Financièrement, s’il a un budget (par ex. un directeur des opérations peut avoir un budget d’optimisation), il le dépensera là plutôt que dans un énième gadget hype. Il est intéressant de noter que ce public est souvent celui qui va poser les questions pointues en phase de sélection (“que se passe-t-il si… ?”, “ai-je la main pour… ?”). S’il obtient de bonnes réponses, il appuiera l’achat. Donc oui, il “paiera” par son vote de confiance et parfois même en temps (par ex. se rendre disponible pour un POC) si ça vaut le coup à ses yeux.

Facteurs de rejet d’Ozaru : Il abandonnera Ozaru si jamais Ozaru le déçoit sur ce qui compte pour lui : la fiabilité, l’explicabilité, le contrôle. Concrètement, si Ozaru se mettait à fournir des résultats obscurs ou erratiques, ou à exclure l’humain du processus, il perdrait ce public. De même, une contradiction non assumée ou un échec mal géré entamera irrémédiablement la confiance. Par exemple, s’il y a un incident et qu’Ozaru (l’organisation Ozaru) joue au chat et à la souris sans donner d’explication claire, le responsable Ops se sentira trahi. Il pourrait alors retourner au statu quo ou chercher une autre solution plus simple qu’il peut contrôler. À noter aussi : si sa hiérarchie abandonne Ozaru, lui n’aura pas le choix (c’est un suiveur en termes de décision finale). Donc il peut abandonner malgré lui si le projet Ozaru se vend mal en interne. D’où l’importance de faire de lui un allié actif dès le début.

Verdict : Archétype très réel et confirmé. C’est probablement le persona qu’on a le moins besoin d’ajuster car la recherche alimente directement ses caractéristiques (on a quasiment pu lire dans leurs pensées via les témoignages). Peut-être faut-il segmenter à l’intérieur : tous les responsables Ops n’ont pas exactement la même réaction (certains sont plus technophiles que d’autres), mais la dominante de “recherche de contrôle et allergie aux solutions opaques” est constante. Ozaru devra s’assurer de parler le langage de la fiabilité avec eux, et d’apporter des garanties tangibles (explicabilité, accompagnement, support réactif en cas de souci).

Archétype 3 : Le Dirigeant traumatisé par l’innovation

C’est qui : Un dirigeant (souvent au niveau COMEX ou DG) qui a vécu de près ou de loin des projets digitaux/IA très décevants par le passé, au point d’en être échaudé. D’après le portrait initial, il/elle se méfie du discours technophile, prône une approche sobre, et a développé une aversion aux promesses flamboyantes de la tech. C’est un peu le blessé de guerre des transformations numériques.

Existence réelle : Oui, et possiblement de plus en plus. Les statistiques sur l’échec des projets IA sont éloquentes (selon Gartner ~80% des projets IA n’atteignent pas leurs objectifs ￼, selon MIT 95% des projets d’IA géné n’apportent pas de ROI ￼). Cela signifie qu’il y a beaucoup de dirigeants qui ont vu de leurs yeux des millions partir en fumée. Les baromètres de confiance montrent aussi une défiance grandissante envers l’innovation effrénée : « 1 personne sur 2 pense que les entreprises gèrent mal l’introduction des innovations » et l’IA est particulièrement divisive ￼ ￼. On rencontre ainsi des CEOs ou directeurs BU qui, en comité restreint, disent “l’IA, j’y crois plus, on a déjà gaspillé X € là-dedans il y a 3 ans”. Ce profil n’est donc pas imaginaire du tout – il suffit de voir le nombre de projets pilotes avortés et d’articles post-mortem “Pourquoi notre projet IA a échoué” pour comprendre qu’il y a beaucoup de “traumatisés” du numérique dans les boards.

Haines et attitudes confirmées : Ce dirigeant est censé haïr le discours technophile creux. Les retours confirment qu’en effet, les grandes déclarations sur la tech ont tendance à le crisper davantage ￼. Par exemple, dans l’étude Edelman déjà citée, on souligne que les envolées lyriques des big tech sur les bienfaits futurs de l’IA ont plutôt pour effet d’accentuer la méfiance du public – un dirigeant traumatisé partage ce ressenti, il a un radar à bullshit hyper développé. Il privilégie les approches sobres, prêtes à renoncer si ça dérape. D’ailleurs, Edelman note que ces dirigeants devraient apprendre à “stopper un projet qui inquiète” plutôt que de s’entêter ￼ – ce qui est exactement l’attitude du dirigeant traumatisé (il n’hésite plus à appuyer sur le bouton rouge si les voyants sont mauvais). Dans les témoignages, on a vu des choses comme : « J’ai déjà entendu toutes ces belles promesses, montrez-moi du concret ou ça ne m’intéresse pas ». Également, ce profil valorise les démarches responsables et la conformité. Il sera celui qui parle de gouvernance, de risques, là où d’autres parleraient features. Donc ses “motivations” (prudence, réalisme) et ses “blocages” (allergie au hype) sont bien observables et cohérents avec l’archétype.

Minoritaire mais stratégique : Il est peut-être minoritaire en image publique (car aujourd’hui encore la mode est au dirigeant innovant flamboyant), mais potentiellement très répandu en privé. Beaucoup de dirigeants n’osent pas dire qu’ils sont traumatisés de peur de passer pour rétrogrades, mais n’en pensent pas moins. Stratégique, oui, car c’est souvent lui qui détient les cordons de la bourse. Si on ne le convainc pas, le projet ne verra pas le jour. On peut même dire que c’est LE décisionnaire économique clé. Ce qui le rend stratégique aussi, c’est qu’il peut être un allié formidable d’Ozaru s’il est rassuré : c’est celui qui donnera le budget et le temps nécessaires pour bien faire les choses (puisqu’il veut éviter les erreurs du passé).

Prêt à payer : Paradoxalement oui, s’il est convaincu. Ce dirigeant a pu sembler radin vis-à-vis des projets innovants (“plus un sou dans ces conneries d’IA !”), mais en réalité il est prêt à investir là où il voit une approche vraiment différente et sécurisée. S’il perçoit Ozaru comme “l’innovation sans le risque irresponsable”, il sortira le chéquier. En fait, ce profil est prêt à payer pour de la tranquillité d’esprit. Tout ce qui peut lui prouver qu’on ne refera pas les erreurs d’hier a de la valeur à ses yeux. Par exemple, un DSI traumatisé par un fiasco ERP sera ensuite disposé à payer cher un audit indépendant qui le rassure sur un nouveau déploiement. De même, il paiera Ozaru s’il y voit un copilote de décision qui agit en conscience des risques, contrairement aux solutions précédentes qui lui ont menti.

Pourquoi abandonnerait-il Ozaru : Il pourrait malgré tout l’abandonner si jamais son traumatisme l’emporte sur son ouverture. C’est-à-dire que s’il voit le moindre signe qu’Ozaru pourrait le mener sur le chemin qu’il redoute (par ex., un coût qui explose, un délai qui dérive, un résultat qui tarde), son réflexe de protection sera de tout stopper. Sa tolérance à l’échec est très faible. Donc Ozaru doit livrer rapidement des preuves tangibles de succès, sinon la sonnette d’alarme retentira. Un autre cas est la pression externe : ce dirigeant peut être poussé vers la porte s’il est perçu comme freinant l’innovation. S’il pense qu’Ozaru va trop à contre-courant de la doxa du marché et que ça met sa carrière en danger, il laissera tomber. Enfin, si jamais un concurrent adopte une approche hype avec (apparemment) du succès, il pourrait être dépassé et contraint par son board de revenir vers des solutions plus “à la mode”. C’est rare mais possible.

Verdict : Archétype validé, avec une intensité de traits sans doute variable selon les personnes. Il n’est pas seulement “traumatisé = conservateur”, il est aussi éduqué par l’échec et recherche une innovation maîtrisée. En cela, il se recoupe un peu avec le décideur lucide (les deux peuvent être la même personne d’ailleurs). La recherche suggère d’insister sur son aspect “en veille” : il surveille tout ce qui pourrait reconfirmer ses craintes. Ozaru devra donc surcommuniquer sur comment il diffère des approches précédentes, comment les erreurs du passé ne se reproduiront pas (par ex., protocoles d’échec explicites, transparence totale, etc.). S’il est convaincu, il deviendra un promoteur discret mais solide d’Ozaru. Sinon, il sera un farouche opposant par principe.

Axe 5 — Axes de différenciation défendables pour Ozaru

Objectif : À partir de toute la matière collectée (alternatives, implicites, frustrations, validation des personas), dégager 3 à 5 axes sur lesquels positionner Ozaru dans le mapping concurrentiel. Ces axes doivent refléter des oppositions pertinentes pour la cible, correspondre à des critères réels de choix, et ouvrir une zone de différenciation où Ozaru peut exceller sans se marginaliser. Sont exclus les axes marketing trop génériques ou les axes théoriques non observables. Voici une short-list d’axes potentiels, argumentés par nos observations terrain :
	•	Transparence & Contrôle vs Opacité & “Boîte Noire” – C’est un axe central qui ressort de multiples points. D’un côté, les solutions/opportunités qui fonctionnent en boîte noire (IA inexplicable, consultants qui opèrent dans le dos du client, automatisations sans garde-fou), de l’autre une approche qui donne de la visibilité et garde l’humain “aux commandes”. Pourquoi c’est pertinent : La peur de l’opacité est un thème transversal chez la cible (responsables ops effrayés par les systèmes qu’ils ne comprennent pas ￼, décideurs qui ne font plus confiance aveuglément, etc.). Un outil ou service qui se positionne résolument sur la transparence (algorithmes explicables, décisions tracées, possibilité d’audit) et le contrôle humain (l’utilisateur peut à tout moment reprendre la main, fixer des limites) aura un avantage concurrentiel clair auprès de ces publics méfiants. Observation terrain : Par exemple, l’étude Edelman note que les gens adhèrent bien plus à l’innovation (IA en particulier) s’ils peuvent contrôler la manière dont elle affecte leur vie ￼. Ozaru peut donc se différencier nettement en se plaçant du côté “contrôlable/transparent” de cet axe, face à des alternatives qui demandent un saut de foi. Cela semble défendable car il est possible de démontrer concrètement cette transparence (via des explications intégrées, des tableaux de bord de décision, etc.), là où d’autres offres ne le feront pas. C’est un axe observable (on peut demander au client : “comprenez-vous comment la décision est prise ?”). Enfin, c’est un axe qui parle aux trois archétypes : le décideur lucide veut de la clarté, l’opérationnel veut voir ce qui se passe, le dirigeant traumatisé veut un truc qu’il peut expliquer au conseil d’administration sans rougir.
	•	Responsabilisation & Falsifiabilité vs Délégation sans filet & Flou des responsabilités – Cet axe oppose les approches où le fournisseur/outil partage le risque et s’engage sur le résultat, face à celles où l’on vous dit “faites-nous confiance” sans jamais assumer en cas de pépin. Pourquoi pertinent : On a vu que l’un des gros points de douleur est l’irresponsabilité diffuse (ex: consultants qui esquivent leur part quand ça échoue ￼). Si Ozaru peut se positionner comme assumant clairement sa part – par exemple en définissant dès le départ comment on gère un échec, en ayant des SLA ou garanties de performance, ou même en modérant les attentes avec honnêteté – il se distinguera fortement. C’est risqué de prime abord (il faut pouvoir tenir ces engagements) mais c’est radicalement différent de la norme actuelle du “best effort flou”. Observations : Un signal très apprécié par la cible serait par exemple un protocole d’échec explicite (“si l’IA se trompe, voici comment on le détecte et corrige, voici qui est responsable de valider…”). Actuellement, toute promesse sans ce filet est perçue négativement ￼. Donc sur cet axe, Ozaru serait du côté de la redevabilité (accountability) tandis que d’autres restent sur la délégation aveugle. On pourrait presque formuler l’axe comme “Assume/Assure vs Esquive/Évite”. Défendable : Oui, car Ozaru peut concevoir son modèle commercial et opérationnel autour de cette idée (par ex, paiement à l’usage réussi, implication contractuelle en cas de problème…). Peu de concurrents traditionnels oseront aller là, c’est donc un espace peu concurrentiel parce que plus engageant. Pour le client, c’est hautement différenciant (il saura faire la différence entre un discours assumé et un vendeur de rêve). Attention toutefois : il faut réellement le prouver sur le terrain, sinon l’axe se retourne en perte de crédibilité.
	•	Clarté Pragmatique vs Mirages Technologiques – Ici on oppose une approche qui privilégie la sobriété intellectuelle et la clarté des bénéfices à une approche qui mise sur l’éblouissement par la technologie et les effets de mode. C’est l’axe No-BS vs Buzz. Pourquoi pertinent : Nos recherches montrent un ras-le-bol du hype chez les décideurs informés ￼. Ils sont lassés des “innovations” qui sonnent creux et veulent qu’on leur parle concrètement (gains mesurables, cas d’usage réalistes). Ozaru a l’opportunité de se positionner comme le contrepoids aux discours utopiques. Observation : Par exemple, la phrase d’un décideur « l’IA ça marche pas, je vais attendre » ￼ illustre que les promesses mirifiques ont décrédibilisé le domaine aux yeux de certains. Sur cet axe, Ozaru serait la solution qui promet moins mais tient plus, focalisée sur des choses claires, mesurables, là où d’autres vendent du rêve (ex: plateformes d’agents “révolutionnaires” qui en réalité plantent 42% du temps ￼). Concrètement, cela peut se traduire par une communication d’Ozaru très factuelle, avec des preuves terrain, vs des concurrents qui montrent surtout des concepts futuristes. Défendable : Oui, car aligné avec l’ADN qu’on souhaite (lucidité). C’est observable dans le réel (il suffit de comparer les campagnes marketing ou la manière de faire des propositions commerciales). C’est un axe sur lequel être radical (dire ses quatre vérités au marché) peut même créer une aura d’honnêteté bienvenue sans isoler Ozaru – au contraire, cela pourrait rallier tous ceux qui n’y croyaient plus.
	•	Approche Augmentante (Humain+IA) vs Automatisation Remplaçante (Humain écarté) – Cet axe distingue les solutions qui visent à outiller et renforcer les humains dans la décision de celles qui cherchent à les remplacer purement et simplement. Pourquoi c’est crucial : Une des grandes craintes relevées est la perte de place de l’humain ￼ ￼. Beaucoup de décideurs et d’opérationnels préfèrent une IA qui les assiste plutôt qu’une IA qui les évince. Ozaru pourrait se positionner carrément sur le créneau “copilote éclairé” versus les alternatives “pilote automatique”. Observations : On voit par exemple que la moitié des sondés ne font pas confiance aux entreprises pour “faire ce qui est juste” avec l’IA ￼, et que l’adhésion à l’IA augmente quand les gens sentent qu’ils gardent la main ￼. Sur le terrain, les solutions qui se vantent de remplacer les employés créent du rejet (ex: on a entendu « les agents IA vont remplacer vos employés » – typiquement le genre de phrase qui fait lever un sourcil réprobateur aux RH et managers ￼). En opposant augmentation vs remplacement, on touche un nerf psychologique très fort : la valeur de l’humain. Ozaru peut se différencier en étant l’outil qui respecte et amplifie l’expertise humaine plutôt que la dévaloriser. Défendable : Tout à fait, car Ozaru peut intégrer dans son fonctionnement la validation humaine, la collaboration IA-humain, etc. Cet axe est visible par la façon dont Ozaru interagit (par ex, toujours demander la décision finale à l’utilisateur, expliquer pour qu’il apprenne, etc.). En face, les concurrents qui vendent du “100% automatisé sans intervention” se positionnent sur l’autre extrême. Les deux positions sont claires; Ozaru choisit celle qui correspond aux aspirations à la fois du décideur lucide (qui veut un outil qui le rend plus fort, pas qui décide à sa place) et de l’opérationnel (qui veut garder son rôle). Même le dirigeant prudent y trouve son compte, car une IA augmentative semble moins risquée qu’une suppression de contrôle humain.
	•	Pilotage Mesuré & Iteratif vs Transformation Massive & Big Bang – Un dernier axe possible serait celui de la méthode de déploiement : petits pas avec mesures continues contre grands projets transformateurs all-in. Raison d’être : Nos recherches suggèrent que de nombreux échecs viennent de programmes trop gros, trop longs, sans métriques claires ￼ ￼. À l’inverse, les succès naissent souvent d’approches agiles, itératives, qui ajustent le tir rapidement ￼. Ozaru pourrait donc revendiquer une approche “scalpel” là où la concurrence utilise le “marteau-pilon”. Observation : Par exemple, un expert LinkedIn conseillait pour l’IA « track adoption and outcomes – pas besoin de grands frameworks, juste du leadership, de la mesure et de l’itération » ￼, au lieu des programmes de change management pharaoniques. C’est exactement l’esprit d’un Ozaru agile. Concurrence : Beaucoup de cabinets ou solutions vendent encore du “grand plan sur 2 ans” qui fait peur aux traumatisés. Ozaru peut se différencier en disant “non, on y va étape par étape, avec vous, en prouvant la valeur à chaque étape, et on peut s’arrêter si ça ne marche pas”. Défendable : C’est crédible si Ozaru organise son offre en modules rapides ou POC courts, etc. C’est observable (ex: temps de déploiement moyen, existence d’un pilote). Et c’est parlant pour la cible (qui a vu les gros éléphants se casser la figure et préfère un projet modulaire qu’on peut arrêter sans tout perdre).

En conclusion, ces axes de différenciation proposés émergent directement des douleurs et désirs constatés sur le terrain. Transparence/Contrôle, Responsabilité, Clarté pragmatique, Augmentation de l’humain, Itérativité mesurée : chacun de ces thèmes oppose Ozaru à une tendance opposée du marché qui frustre la cible. En se positionnant résolument du bon côté de ces axes, Ozaru peut être radical sans s’isoler – car ce radicalisme répond aux attentes latentes de la cible, même si le marché jusqu’ici ne les a pas bien servies. Il faudra probablement affiner et prioriser (tous ne pourront pas être mis en avant simultanément de façon lisible), mais 3 à 5 axes bien choisis parmi ceux-ci donneront au mapping concurrentiel Ozaru une colonne vertébrale crédible et séduisante, car enracinée dans la réalité observée et non des slogans génériques.

Règles de discipline appliquées et conclusion lucide

Tout au long de cette recherche, nous avons veillé à ne rien considérer comme acquis sans le confronter à des signaux observables. Chaque intuition a été vérifiée (par ex., l’idée que “le vrai concurrent est le statu quo” est confirmée par des témoignages sur le status quo bias ￼). Nous avons activement cherché des contre-exemples – par exemple, y a-t-il des décideurs qui aiment le hype ? (oui il y en a, mais on a vu que leur enthousiasme peut les aveugler, ce que note Edelman ￼). Aucun élément fragilisant pour Ozaru n’a été occulté : au contraire, les frustrations et échecs du marché actuel, même inconfortables, ont été documentés car ils pointent où Ozaru doit intervenir prudemment.

Sortie attendue de la recherche : Les résultats ci-dessus fournissent à Ozaru une vision clarifiée des alternatives réelles (qui vont bien au-delà des concurrents directs et incluent l’inaction et les comportements), une validation nuancée du cœur de cible psychographique (les archétypes existent mais doivent être adressés chacun finement), et une base factuelle solide pour construire un mapping concurrentiel différenciant (des axes fondés sur des oppositions tangibles issues du terrain). Nous avons également mis en lumière plusieurs angles morts potentiels du positionnement actuel d’Ozaru – par exemple, l’importance de rassurer sur la responsabilité partagée, ou la nécessité d’éviter tout langage marketing creux sous peine de perdre les décideurs lucides et traumatisés.

En définitive, cette recherche a cherché non pas à conforter Ozaru dans ses convictions, mais à révéler la réalité du terrain. Les conclusions invitent possiblement à ajuster certaines orientations de positionnement. Si elles remettent en question des hypothèses initiales, il faudra les intégrer sans concession. La cohérence d’Ozaru se construira en se confrontant honnêtement aux faits, fussent-ils inconfortables, plutôt qu’en cherchant à les arranger. Ce rapport de recherche approfondie se veut ainsi une boussole franche pour la suite de la démarche stratégique Ozaru, afin de fonder le mapping concurrentiel sur du réel et non de l’auto-persuasion.

Clause de lucidité : Tout au long du processus, nous avons gardé en tête que cette recherche n’est pas là pour “rassurer” Ozaru ou confirmer ce qu’il espère entendre, mais bien pour apporter la vision la plus claire et objective possible. Les éléments récoltés – du consultant cynique sur Reddit aux statistiques brutales des échecs IA – peuvent sembler rudes, mais ils constituent un vaccin contre la complaisance. En les regardant en face, Ozaru maximise ses chances de se positionner avec justesse et d’éviter les erreurs de ceux qui l’ont précédé. Le chemin vers une différenciation forte est étroit mais identifiable ; grâce à cette recherche, Ozaru sait mieux où il doit marcher… et où surtout il ne doit pas mettre le pied.

Sources citées : Les informations et citations proviennent de divers articles, études et témoignages connectés au sujet : LinkedIn (retours d’expérience sur l’échec des projets IA ￼ ￼…), articles spécialisés (ex: blog Cenisis sur les tableaux de bord ￼, étude Edelman sur la confiance ￼, tribune TechPM sur le ROI de l’IA ￼…), forums publics (Reddit consulting ￼…), et analyses sectorielles (Flint “Génération IA” sur les agents ￼, Smart Impact sur les biais d’adoption ￼, etc.). Chaque citation en exergue dans le texte renvoie à sa source originale pour vérification et contexte supplémentaire. Ce corpus a permis d’étayer rigoureusement chaque constat et d’assurer que la “vérité stratégique” recherchée repose sur du concret vérifiable et non sur des intuitions vagues.

￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼
